{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a multiclassification problem the limitations like, unbalanced data and more number of classes are present, which can be addressed using different approaches like SMOTE algorithm, ONE VS One/ One Vs REST binary classifiers, and Linear discriminant analysis.\n",
    "First the issue of unbalanced data is analysed by building models on the unbalanced data and then balancing the data using SMOTE algorithm and then the performance of the models on the balanced data is verified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sklearn as sk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix,precision_score, recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.read_csv(\"train_CloudCondition.csv\",low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 71428 entries, 0 to 71427\n",
      "Data columns (total 12 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   Day                         71428 non-null  int64  \n",
      " 1   Cloud_Condition             71428 non-null  object \n",
      " 2   Rain_OR_SNOW                71313 non-null  object \n",
      " 3   Temperature (C)             71176 non-null  object \n",
      " 4   Apparent Temperature (C)    71425 non-null  float64\n",
      " 5   Humidity                    71427 non-null  float64\n",
      " 6   Wind Speed (km/h)           71426 non-null  float64\n",
      " 7   Wind Bearing (degrees)      71391 non-null  float64\n",
      " 8   Visibility (km)             71408 non-null  float64\n",
      " 9   Pressure (millibars)        71363 non-null  float64\n",
      " 10  Condensation                71428 non-null  object \n",
      " 11  Solar irradiance intensity  71428 non-null  int64  \n",
      "dtypes: float64(6), int64(2), object(4)\n",
      "memory usage: 6.5+ MB\n"
     ]
    }
   ],
   "source": [
    "#The temperature column is imported as datatype object so if any invalid values are present in the data need to be checked.\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Day', 'Cloud_Condition', 'Rain_OR_SNOW', 'Temperature (C)',\n",
       "       'Apparent Temperature (C)', 'Humidity', 'Wind Speed (km/h)',\n",
       "       'Wind Bearing (degrees)', 'Visibility (km)', 'Pressure (millibars)',\n",
       "       'Condensation', 'Solar irradiance intensity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1     2     3 ... 79998 79999 80000] ['Partly Cloudy' 'Light Rain' 'Breezy and Dry' 'Overcast' 'Foggy'\n",
      " 'Breezy and Mostly Cloudy' 'Clear' 'Breezy and Partly Cloudy'\n",
      " 'Breezy and Overcast' 'Humid and Mostly Cloudy' 'Mostly Cloudy'\n",
      " 'Humid and Partly Cloudy' 'Windy and Foggy' 'Windy and Overcast'\n",
      " 'Breezy and Foggy' 'Windy and Partly Cloudy' 'Breezy'\n",
      " 'Dry and Partly Cloudy' 'Windy and Mostly Cloudy'\n",
      " 'Dangerously Windy and Partly Cloudy' 'Dry' 'Windy' 'Humid and Overcast'\n",
      " 'Drizzle' 'Windy and Dry' 'Dry and Mostly Cloudy'] ['rain' 'snow' nan] ['-13' '15' '33' '30' '27' '-17' '-5' '-14' '10' '7' '9' '20' '3' '29'\n",
      " '-8' '-15' '-20' '36' '32' '6' '17' '28' '-21' '23' '-4' '25' '-7' '16'\n",
      " '39' '-1' '13' '35' '22' '12' '14' '1' '8' '-3' '38' '5' '37' '-10' '19'\n",
      " '34' '26' '0' '24' '11' '21' '-9' '-2' '4' '-19' '-6' '2' '-16' '-11'\n",
      " '18' '31' '-18' '-12' nan '-'] [-19.   5. -12.  36.  30.  33.  21.  -1. -15.  35. -24.  22.  28. -27.\n",
      "   7.   2. -14.  13. -25. -26.   0.  27.   1.  29.  17.  31.  10.  26.\n",
      "  -4.  15.  37.  -3.  11.   9.  23. -23.  34.   4.  24.  -5.  19.  20.\n",
      " -16.  38.  -7. -22.  12.  -6.  -2.  18. -11. -20.  25. -18. -17.   8.\n",
      " -13.  14.  16.   6.  -9. -21. -10.   3.  nan  -8.  32.] [0.13436424 0.84743374 0.76377462 ... 0.49607649 0.78316099 0.1915549 ] [17.  8. 32. 15. 63. 57. 60. 48. 26. 12. 62.  3. 49. 55.  0. 34. 29. 13.\n",
      " 40.  2.  1. 27. 54. 28. 56. 44. 58. 37. 53. 23. 42. 24. 38. 36. 50.  4.\n",
      " 61. 31. 51. 22. 46. 47. 11. 20.  5. 39. 21. 25. 45. 16.  7. 52.  9. 10.\n",
      " 35. 14. 41. 43. 33. 18.  6. 30. 19. 59. nan] [ 68. 291.  32. 130.  60. 253. 230. 241. 333. 194. 107.  48. 249.  14.\n",
      " 199. 221. 311.   1. 356. 228. 136. 117. 302.  52. 162.  15.  11.  13.\n",
      " 332. 277.   4. 195. 351. 110. 216. 270. 113. 224. 283. 119. 176. 118.\n",
      " 346. 112. 235. 148. 213. 284. 328.  51.  95. 322. 151.  61. 170. 256.\n",
      " 259. 343.  97. 155. 145. 300. 255. 258. 201. 301.  17. 245. 124. 206.\n",
      " 212. 340.  88. 187. 280. 359. 345. 191.  44. 339. 260.  55.  83. 266.\n",
      " 189. 250. 240.  22. 157. 314. 303. 296. 331.  87.  86. 257. 116.   6.\n",
      " 102. 276. 207. 263. 295. 180. 137. 337.   2. 196. 262.  66. 265. 287.\n",
      " 105. 218.  28. 246. 186. 211. 248. 182. 177.   0. 275. 319. 313. 169.\n",
      " 234. 307. 325.  90. 281. 299.  92.  46. 282.  16. 344.  36.  42.   8.\n",
      " 231.   7. 143. 127.  56.  94.  35.  85.  81. 336. 139. 150. 232. 164.\n",
      " 254. 242.  58.  12. 159. 197. 175. 215.  96. 132. 129. 261. 310.  10.\n",
      " 115.   9. 203.  74.  18.  82. 347. 278. 355. 264. 114. 268. 202. 294.\n",
      " 323.  30. 152.  64. 108.  24. 156.  39. 158. 289.  19. 111. 318. 193.\n",
      "  50. 293.  99. 252.  53. 166. 205. 144.  80. 167. 288.  69. 173. 219.\n",
      " 109.  49. 273. 272. 120.  33.  20.  43. 188. 174. 149. 309. 208.  37.\n",
      "  75. 292.  41. 141.  23. 122.  59. 348. 123. 222. 244. 161. 106.   5.\n",
      " 305. 163. 200. 160. 204. 233.  57. 128. 316. 352. 338.  93. 101. 126.\n",
      " 184.  45. 229. 329.  21. 125. 171.  47.  38. 183.  78.  91.  76.  72.\n",
      "  54. 308. 279. 353. 153. 341. 349. 220. 330.  31. 354. 181.  70.   3.\n",
      " 327. 172. 286. 312. 334. 140. 104. 190.  84. 237. 304.  63.  79.  26.\n",
      " 326. 178. 321.  71. 315. 358. 227. 209. 142. 133. 251.  62. 223. 165.\n",
      " 226. 179. 285. 306. 236. 317. 342. 271. 269.  34. 324. 138. 135. 210.\n",
      " 350.  77. 239. 121. 357. 267.  25. 247. 168. 320. 297. 134. 225.  40.\n",
      " 147. 100. 198.  29. 274.  98.  89. 217.  27.  65. 154. 185. 131. 103.\n",
      "  67. 214. 290.  73. 243. 335. 192. 298. 238. 146.  nan] [ 4.  2.  8.  3. 15. 14. 12.  6.  0. 13.  7. 10. 16. 11.  9.  5.  1. nan] [1008. 1036. 1004. 1016. 1007. 1031. 1028. 1030. 1041. 1024. 1013. 1006.\n",
      "   nan 1027. 1038. 1000. 1044. 1017. 1046. 1014. 1037. 1020. 1001. 1034.\n",
      " 1043. 1033. 1035. 1022. 1029. 1018. 1026. 1011. 1040. 1021. 1045. 1032.\n",
      " 1042. 1012. 1019. 1025. 1002. 1015. 1023. 1005. 1010. 1039. 1003. 1009.] ['Frost' 'Dry' 'Fog' 'Mist'] [1068 1291 1433 1410 1391 1032 1130 1060 1253 1389 1230 1241 1333 1194\n",
      " 1403 1107 1048 1249 1014 1457 1427 1199 1221 1311 1390 1392 1001 1356\n",
      " 1228 1136 1369 1117 1302 1483 1052 1461 1162 1015 1011 1013 1332 1277\n",
      " 1004 1480 1451 1195 1351 1110 1496 1216 1371 1270 1113 1224 1283 1119\n",
      " 1176 1118 1346 1112 1235 1487 1148 1474 1213 1428 1469 1284 1472 1328\n",
      " 1051 1095 1322 1370 1440 1151 1061 1380 1170 1458 1498 1364 1256 1479\n",
      " 1495 1259 1424 1466 1343 1097 1155 1145 1300 1255 1481 1258 1201 1301\n",
      " 1436 1017 1245 1124 1408 1206 1212 1340 1088 1187 1280 1359 1397 1345\n",
      " 1377 1191 1044 1339 1260 1055 1398 1083 1266 1430 1189 1250 1375 1240\n",
      " 1022 1157 1360 1434 1314 1303 1296 1331 1087 1086 1257 1116 1006 1394\n",
      " 1102 1276 1471 1207 1263 1295 1180 1465 1137 1337 1490 1373 1002 1196\n",
      " 1401 1438 1420 1488 1453 1379 1262 1414 1066 1265 1287 1105 1218 1486\n",
      " 1028 1246 1445 1186 1211 1248 1416 1182 1177 1000 1275 1319 1402 1313\n",
      " 1169 1234 1307 1411 1325 1090 1281 1299 1092 1046 1282 1435 1418 1476\n",
      " 1016 1344 1036 1042 1444 1008 1231 1007 1386 1143 1127 1056 1094 1035\n",
      " 1085 1081 1336 1139 1150 1232 1164 1254 1242 1058 1012 1159 1197 1175\n",
      " 1215 1407 1096 1132 1129 1460 1261 1500 1494 1310 1499 1010 1115 1009\n",
      " 1203 1074 1018 1368 1491 1082 1347 1278 1426 1355 1264 1114 1268 1202\n",
      " 1294 1323 1030 1152 1064 1108 1448 1024 1156 1439 1039 1158 1289 1449\n",
      " 1019 1419 1111 1492 1423 1399 1318 1193 1050 1293 1459 1099 1252 1053\n",
      " 1166 1446 1205 1144 1080 1167 1415 1288 1400 1069 1173 1219 1109 1049\n",
      " 1477 1468 1273 1393 1272 1120 1033 1020 1043 1388 1188 1174 1149 1309\n",
      " 1366 1454 1208 1037 1443 1075 1292 1041 1456 1473 1141 1023 1422 1404\n",
      " 1122 1059 1348 1123 1432 1222 1493 1412 1244 1161 1106 1005 1305 1163\n",
      " 1200 1160 1204 1467 1233 1057 1128 1316 1352 1338 1093 1101 1126 1184\n",
      " 1045 1385 1229 1329 1021 1405 1125 1171 1413 1047 1038 1384 1183 1441\n",
      " 1078 1091 1076 1072 1054 1363 1470 1308 1279 1462 1464 1382 1353 1153\n",
      " 1365 1341 1349 1220 1406 1330 1031 1354 1181 1070 1003 1327 1374 1489\n",
      " 1172 1286 1312 1372 1334 1140 1497 1452 1104 1190 1084 1237 1304 1063\n",
      " 1079 1482 1387 1026 1367 1326 1178 1321 1071 1315 1431 1358 1227 1209\n",
      " 1142 1383 1133 1437 1251 1062 1450 1223 1165 1226 1179 1285 1306 1378\n",
      " 1236 1381 1317 1342 1271 1269 1034 1324 1138 1417 1135 1362 1210 1447\n",
      " 1350 1077 1239 1484 1121 1357 1425 1267 1025 1376 1247 1168 1361 1475\n",
      " 1320 1297 1134 1225 1455 1040 1147 1100 1198 1029 1463 1274 1098 1478\n",
      " 1089 1217 1027 1065 1409 1154 1185 1429 1131 1103 1067 1395 1396 1214\n",
      " 1290 1073 1485 1243 1335 1192 1298 1238 1146 1421 1442]\n"
     ]
    }
   ],
   "source": [
    "#To check if any special characters or invalid values are present in the data\n",
    "#There were some invalid values like '-' in the \"Temperature\" column and no invalid values in other columns.\n",
    "print(data.Day.unique(),data.Cloud_Condition.unique(),data.Rain_OR_SNOW.unique(),data[\"Temperature (C)\"].unique(), \n",
    "     data[\"Apparent Temperature (C)\"].unique(),data.Humidity.unique(),data[\"Wind Speed (km/h)\"].unique(),\n",
    "      data[\"Wind Bearing (degrees)\"].unique(),data[\"Visibility (km)\"].unique(),data[\"Pressure (millibars)\"].unique(),\n",
    "      data.Condensation.unique(),data[\"Solar irradiance intensity\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Cloud_Condition</th>\n",
       "      <th>Rain_OR_SNOW</th>\n",
       "      <th>Temperature_(C)</th>\n",
       "      <th>Apparent_Temperature_(C)</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind_Speed_(km/h)</th>\n",
       "      <th>Wind_Bearing_(degrees)</th>\n",
       "      <th>Visibility_(km)</th>\n",
       "      <th>Pressure_(millibars)</th>\n",
       "      <th>Condensation</th>\n",
       "      <th>Solar_irradiance_intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "      <td>rain</td>\n",
       "      <td>-13</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>0.134364</td>\n",
       "      <td>17.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>Frost</td>\n",
       "      <td>1068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "      <td>rain</td>\n",
       "      <td>15</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.847434</td>\n",
       "      <td>8.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1036.0</td>\n",
       "      <td>Frost</td>\n",
       "      <td>1291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "      <td>rain</td>\n",
       "      <td>33</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>0.763775</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1004.0</td>\n",
       "      <td>Dry</td>\n",
       "      <td>1433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "      <td>snow</td>\n",
       "      <td>30</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.255069</td>\n",
       "      <td>15.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>Dry</td>\n",
       "      <td>1410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "      <td>snow</td>\n",
       "      <td>27</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.495435</td>\n",
       "      <td>63.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>Fog</td>\n",
       "      <td>1391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71423</th>\n",
       "      <td>79996</td>\n",
       "      <td>Foggy</td>\n",
       "      <td>rain</td>\n",
       "      <td>39</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.243553</td>\n",
       "      <td>19.0</td>\n",
       "      <td>347.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>Frost</td>\n",
       "      <td>1269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71424</th>\n",
       "      <td>79997</td>\n",
       "      <td>Foggy</td>\n",
       "      <td>rain</td>\n",
       "      <td>8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.913108</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1031.0</td>\n",
       "      <td>Dry</td>\n",
       "      <td>1224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71425</th>\n",
       "      <td>79998</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "      <td>rain</td>\n",
       "      <td>28</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>0.496076</td>\n",
       "      <td>2.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>Frost</td>\n",
       "      <td>1463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71426</th>\n",
       "      <td>79999</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "      <td>rain</td>\n",
       "      <td>-16</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.783161</td>\n",
       "      <td>44.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>Fog</td>\n",
       "      <td>1251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71427</th>\n",
       "      <td>80000</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "      <td>rain</td>\n",
       "      <td>-15</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.191555</td>\n",
       "      <td>38.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>Fog</td>\n",
       "      <td>1258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71428 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Day Cloud_Condition Rain_OR_SNOW Temperature_(C)  \\\n",
       "0          1   Partly Cloudy         rain             -13   \n",
       "1          2   Partly Cloudy         rain              15   \n",
       "2          3   Partly Cloudy         rain              33   \n",
       "3          4   Partly Cloudy         snow              30   \n",
       "4          5   Partly Cloudy         snow              27   \n",
       "...      ...             ...          ...             ...   \n",
       "71423  79996           Foggy         rain              39   \n",
       "71424  79997           Foggy         rain               8   \n",
       "71425  79998   Mostly Cloudy         rain              28   \n",
       "71426  79999   Mostly Cloudy         rain             -16   \n",
       "71427  80000   Mostly Cloudy         rain             -15   \n",
       "\n",
       "       Apparent_Temperature_(C)  Humidity  Wind_Speed_(km/h)  \\\n",
       "0                         -19.0  0.134364               17.0   \n",
       "1                           5.0  0.847434                8.0   \n",
       "2                         -12.0  0.763775               32.0   \n",
       "3                          36.0  0.255069               15.0   \n",
       "4                          30.0  0.495435               63.0   \n",
       "...                         ...       ...                ...   \n",
       "71423                      31.0  0.243553               19.0   \n",
       "71424                       4.0  0.913108                1.0   \n",
       "71425                     -22.0  0.496076                2.0   \n",
       "71426                      -3.0  0.783161               44.0   \n",
       "71427                       8.0  0.191555               38.0   \n",
       "\n",
       "       Wind_Bearing_(degrees)  Visibility_(km)  Pressure_(millibars)  \\\n",
       "0                        68.0              4.0                1008.0   \n",
       "1                       291.0              2.0                1036.0   \n",
       "2                        32.0              8.0                1004.0   \n",
       "3                       130.0              3.0                1016.0   \n",
       "4                        60.0             15.0                1007.0   \n",
       "...                       ...              ...                   ...   \n",
       "71423                   347.0             14.0                1013.0   \n",
       "71424                   101.0              8.0                1031.0   \n",
       "71425                   149.0              7.0                1032.0   \n",
       "71426                   266.0             11.0                1019.0   \n",
       "71427                   154.0              6.0                1023.0   \n",
       "\n",
       "      Condensation  Solar_irradiance_intensity  \n",
       "0            Frost                        1068  \n",
       "1            Frost                        1291  \n",
       "2              Dry                        1433  \n",
       "3              Dry                        1410  \n",
       "4              Fog                        1391  \n",
       "...            ...                         ...  \n",
       "71423        Frost                        1269  \n",
       "71424          Dry                        1224  \n",
       "71425        Frost                        1463  \n",
       "71426          Fog                        1251  \n",
       "71427          Fog                        1258  \n",
       "\n",
       "[71428 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Renaming the columns to replace space with underscore.\n",
    "data.rename(columns={'Temperature (C)' : \"Temperature_(C)\",'Apparent Temperature (C)' : 'Apparent_Temperature_(C)',\n",
    "                     'Wind Speed (km/h)' : 'Wind_Speed_(km/h)','Wind Bearing (degrees)' : 'Wind_Bearing_(degrees)', \n",
    "                     'Visibility (km)' : 'Visibility_(km)', 'Pressure (millibars)' : 'Pressure_(millibars)',\n",
    "       'Solar irradiance intensity' : 'Solar_irradiance_intensity'}, inplace = True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "252"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the null values in the temperature column before replacing the invalid values\n",
    "data[\"Temperature_(C)\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing the invalid values as null values\n",
    "data[\"Temperature_(C)\"].replace(\"-\", np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['-13', '15', '33', '30', '27', '-17', '-5', '-14', '10', '7', '9',\n",
       "       '20', '3', '29', '-8', '-15', '-20', '36', '32', '6', '17', '28',\n",
       "       '-21', '23', '-4', '25', '-7', '16', '39', '-1', '13', '35', '22',\n",
       "       '12', '14', '1', '8', '-3', '38', '5', '37', '-10', '19', '34',\n",
       "       '26', '0', '24', '11', '21', '-9', '-2', '4', '-19', '-6', '2',\n",
       "       '-16', '-11', '18', '31', '-18', '-12', nan], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To check if the invalid value is replaced\n",
    "data[\"Temperature_(C)\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "253"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to check if the number of null values is increased.\n",
    "data[\"Temperature_(C)\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now the datatype of temparature column can be changed to float.\n",
    "data['Temperature_(C)'] = data['Temperature_(C)'].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Cloud_Condition</th>\n",
       "      <th>Rain_OR_SNOW</th>\n",
       "      <th>Temperature_(C)</th>\n",
       "      <th>Apparent_Temperature_(C)</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind_Speed_(km/h)</th>\n",
       "      <th>Wind_Bearing_(degrees)</th>\n",
       "      <th>Visibility_(km)</th>\n",
       "      <th>Pressure_(millibars)</th>\n",
       "      <th>Condensation</th>\n",
       "      <th>Solar_irradiance_intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "      <td>rain</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>0.134364</td>\n",
       "      <td>17.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>Frost</td>\n",
       "      <td>1068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "      <td>rain</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.847434</td>\n",
       "      <td>8.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1036.0</td>\n",
       "      <td>Frost</td>\n",
       "      <td>1291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "      <td>rain</td>\n",
       "      <td>33.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>0.763775</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1004.0</td>\n",
       "      <td>Dry</td>\n",
       "      <td>1433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "      <td>snow</td>\n",
       "      <td>30.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.255069</td>\n",
       "      <td>15.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>Dry</td>\n",
       "      <td>1410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "      <td>snow</td>\n",
       "      <td>27.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.495435</td>\n",
       "      <td>63.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>Fog</td>\n",
       "      <td>1391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Day Cloud_Condition Rain_OR_SNOW  Temperature_(C)  \\\n",
       "0    1   Partly Cloudy         rain            -13.0   \n",
       "1    2   Partly Cloudy         rain             15.0   \n",
       "2    3   Partly Cloudy         rain             33.0   \n",
       "3    4   Partly Cloudy         snow             30.0   \n",
       "4    5   Partly Cloudy         snow             27.0   \n",
       "\n",
       "   Apparent_Temperature_(C)  Humidity  Wind_Speed_(km/h)  \\\n",
       "0                     -19.0  0.134364               17.0   \n",
       "1                       5.0  0.847434                8.0   \n",
       "2                     -12.0  0.763775               32.0   \n",
       "3                      36.0  0.255069               15.0   \n",
       "4                      30.0  0.495435               63.0   \n",
       "\n",
       "   Wind_Bearing_(degrees)  Visibility_(km)  Pressure_(millibars) Condensation  \\\n",
       "0                    68.0              4.0                1008.0        Frost   \n",
       "1                   291.0              2.0                1036.0        Frost   \n",
       "2                    32.0              8.0                1004.0          Dry   \n",
       "3                   130.0              3.0                1016.0          Dry   \n",
       "4                    60.0             15.0                1007.0          Fog   \n",
       "\n",
       "   Solar_irradiance_intensity  \n",
       "0                        1068  \n",
       "1                        1291  \n",
       "2                        1433  \n",
       "3                        1410  \n",
       "4                        1391  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The data is about weather conditions with 11 input variables which are the different conditions that affect the weather. \n",
    "#target variable is cloud_condition which is classified into 26 different classes.\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mostly Cloudy                          22017\n",
       "Partly Cloudy                          17613\n",
       "Overcast                               13612\n",
       "Clear                                   9719\n",
       "Foggy                                   5900\n",
       "Breezy and Dry                           656\n",
       "Breezy and Mostly Cloudy                 473\n",
       "Breezy and Overcast                      454\n",
       "Breezy and Partly Cloudy                 350\n",
       "Light Rain                               214\n",
       "Dry and Partly Cloudy                     86\n",
       "Windy and Partly Cloudy                   63\n",
       "Breezy                                    45\n",
       "Windy and Overcast                        43\n",
       "Dry                                       34\n",
       "Breezy and Foggy                          34\n",
       "Humid and Mostly Cloudy                   32\n",
       "Windy and Mostly Cloudy                   32\n",
       "Humid and Partly Cloudy                   17\n",
       "Dry and Mostly Cloudy                     14\n",
       "Windy                                      5\n",
       "Humid and Overcast                         5\n",
       "Drizzle                                    5\n",
       "Windy and Foggy                            3\n",
       "Windy and Dry                              1\n",
       "Dangerously Windy and Partly Cloudy        1\n",
       "Name: Cloud_Condition, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#From the below record counts we can see that the data is unbalanced with unequal number of records for each class.\n",
    "data['Cloud_Condition'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 71428 entries, 0 to 71427\n",
      "Data columns (total 12 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   Day                         71428 non-null  int64  \n",
      " 1   Cloud_Condition             71428 non-null  object \n",
      " 2   Rain_OR_SNOW                71313 non-null  object \n",
      " 3   Temperature_(C)             71175 non-null  float64\n",
      " 4   Apparent_Temperature_(C)    71425 non-null  float64\n",
      " 5   Humidity                    71427 non-null  float64\n",
      " 6   Wind_Speed_(km/h)           71426 non-null  float64\n",
      " 7   Wind_Bearing_(degrees)      71391 non-null  float64\n",
      " 8   Visibility_(km)             71408 non-null  float64\n",
      " 9   Pressure_(millibars)        71363 non-null  float64\n",
      " 10  Condensation                71428 non-null  object \n",
      " 11  Solar_irradiance_intensity  71428 non-null  int64  \n",
      "dtypes: float64(7), int64(2), object(3)\n",
      "memory usage: 6.5+ MB\n"
     ]
    }
   ],
   "source": [
    "#From the info of the data there are null records in some coulmns.\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Day                             0\n",
       "Cloud_Condition                 0\n",
       "Rain_OR_SNOW                  115\n",
       "Temperature_(C)               253\n",
       "Apparent_Temperature_(C)        3\n",
       "Humidity                        1\n",
       "Wind_Speed_(km/h)               2\n",
       "Wind_Bearing_(degrees)         37\n",
       "Visibility_(km)                20\n",
       "Pressure_(millibars)           65\n",
       "Condensation                    0\n",
       "Solar_irradiance_intensity      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To check the number of null records in each column\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Missing values could be imputed with mean/median values in numerical features and mode values in categorical features.\n",
    "#But it should be done based on the preexisting knowledge on the subject if its done without any preunderstanding \n",
    "#it might affect the quality of the data, so to avoid that, the null value records are removed here which is about 490 records,\n",
    "#though it might result in loss of data but since it is less compared to the total records here it might not affect much.\n",
    "data=data.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mostly Cloudy                          21860\n",
       "Partly Cloudy                          17526\n",
       "Overcast                               13506\n",
       "Clear                                   9648\n",
       "Foggy                                   5871\n",
       "Breezy and Dry                           630\n",
       "Breezy and Mostly Cloudy                 467\n",
       "Breezy and Overcast                      452\n",
       "Breezy and Partly Cloudy                 350\n",
       "Light Rain                               209\n",
       "Dry and Partly Cloudy                     86\n",
       "Windy and Partly Cloudy                   63\n",
       "Breezy                                    45\n",
       "Windy and Overcast                        42\n",
       "Dry                                       34\n",
       "Breezy and Foggy                          34\n",
       "Humid and Mostly Cloudy                   32\n",
       "Windy and Mostly Cloudy                   32\n",
       "Humid and Partly Cloudy                   17\n",
       "Dry and Mostly Cloudy                     14\n",
       "Windy                                      5\n",
       "Humid and Overcast                         5\n",
       "Drizzle                                    5\n",
       "Windy and Foggy                            3\n",
       "Windy and Dry                              1\n",
       "Dangerously Windy and Partly Cloudy        1\n",
       "Name: Cloud_Condition, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To check if the removal of null value records has changed the percentage distribution of the class, as the class with less \n",
    "#records are not changed only the class with more records have been changed as a result of removing the null values.\n",
    "data['Cloud_Condition'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data with the unbalalnced distribution of classes is used for model building.\n",
    "Using algorithms like KNN, Decision tree, SVM, Random Forest and logistic regression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 70938 entries, 0 to 71427\n",
      "Data columns (total 12 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   Day                         70938 non-null  int64  \n",
      " 1   Cloud_Condition             70938 non-null  object \n",
      " 2   Rain_OR_SNOW                70938 non-null  object \n",
      " 3   Temperature_(C)             70938 non-null  float64\n",
      " 4   Apparent_Temperature_(C)    70938 non-null  float64\n",
      " 5   Humidity                    70938 non-null  float64\n",
      " 6   Wind_Speed_(km/h)           70938 non-null  float64\n",
      " 7   Wind_Bearing_(degrees)      70938 non-null  float64\n",
      " 8   Visibility_(km)             70938 non-null  float64\n",
      " 9   Pressure_(millibars)        70938 non-null  float64\n",
      " 10  Condensation                70938 non-null  object \n",
      " 11  Solar_irradiance_intensity  70938 non-null  int64  \n",
      "dtypes: float64(7), int64(2), object(3)\n",
      "memory usage: 7.0+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Cloud_Condition</th>\n",
       "      <th>Rain_OR_SNOW</th>\n",
       "      <th>Temperature_(C)</th>\n",
       "      <th>Apparent_Temperature_(C)</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind_Speed_(km/h)</th>\n",
       "      <th>Wind_Bearing_(degrees)</th>\n",
       "      <th>Visibility_(km)</th>\n",
       "      <th>Pressure_(millibars)</th>\n",
       "      <th>Condensation</th>\n",
       "      <th>Solar_irradiance_intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>70938.000000</td>\n",
       "      <td>70938</td>\n",
       "      <td>70938</td>\n",
       "      <td>70938.000000</td>\n",
       "      <td>70938.000000</td>\n",
       "      <td>70938.000000</td>\n",
       "      <td>70938.000000</td>\n",
       "      <td>70938.000000</td>\n",
       "      <td>70938.000000</td>\n",
       "      <td>70938.000000</td>\n",
       "      <td>70938</td>\n",
       "      <td>70938.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "      <td>rain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mist</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>21860</td>\n",
       "      <td>61992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21531</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>37239.108997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.958499</td>\n",
       "      <td>5.553469</td>\n",
       "      <td>0.501019</td>\n",
       "      <td>31.526939</td>\n",
       "      <td>179.205658</td>\n",
       "      <td>8.015027</td>\n",
       "      <td>1022.979249</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1249.685162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>22185.777966</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.631349</td>\n",
       "      <td>19.092730</td>\n",
       "      <td>0.289413</td>\n",
       "      <td>18.509038</td>\n",
       "      <td>103.733352</td>\n",
       "      <td>4.908782</td>\n",
       "      <td>13.559313</td>\n",
       "      <td>NaN</td>\n",
       "      <td>144.827495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21.000000</td>\n",
       "      <td>-27.000000</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>18443.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-6.000000</td>\n",
       "      <td>-11.000000</td>\n",
       "      <td>0.249236</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1011.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1124.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>36177.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.501566</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1023.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1249.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>53989.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.751925</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>269.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1035.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1375.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>80000.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.999990</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>359.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1046.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1500.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Day Cloud_Condition Rain_OR_SNOW  Temperature_(C)  \\\n",
       "count   70938.000000           70938        70938     70938.000000   \n",
       "unique           NaN              26            2              NaN   \n",
       "top              NaN   Mostly Cloudy         rain              NaN   \n",
       "freq             NaN           21860        61992              NaN   \n",
       "mean    37239.108997             NaN          NaN         8.958499   \n",
       "std     22185.777966             NaN          NaN        17.631349   \n",
       "min         1.000000             NaN          NaN       -21.000000   \n",
       "25%     18443.250000             NaN          NaN        -6.000000   \n",
       "50%     36177.500000             NaN          NaN         9.000000   \n",
       "75%     53989.750000             NaN          NaN        24.000000   \n",
       "max     80000.000000             NaN          NaN        39.000000   \n",
       "\n",
       "        Apparent_Temperature_(C)      Humidity  Wind_Speed_(km/h)  \\\n",
       "count               70938.000000  70938.000000       70938.000000   \n",
       "unique                       NaN           NaN                NaN   \n",
       "top                          NaN           NaN                NaN   \n",
       "freq                         NaN           NaN                NaN   \n",
       "mean                    5.553469      0.501019          31.526939   \n",
       "std                    19.092730      0.289413          18.509038   \n",
       "min                   -27.000000      0.000019           0.000000   \n",
       "25%                   -11.000000      0.249236          16.000000   \n",
       "50%                     5.000000      0.501566          31.000000   \n",
       "75%                    22.000000      0.751925          48.000000   \n",
       "max                    38.000000      0.999990          63.000000   \n",
       "\n",
       "        Wind_Bearing_(degrees)  Visibility_(km)  Pressure_(millibars)  \\\n",
       "count             70938.000000     70938.000000          70938.000000   \n",
       "unique                     NaN              NaN                   NaN   \n",
       "top                        NaN              NaN                   NaN   \n",
       "freq                       NaN              NaN                   NaN   \n",
       "mean                179.205658         8.015027           1022.979249   \n",
       "std                 103.733352         4.908782             13.559313   \n",
       "min                   0.000000         0.000000           1000.000000   \n",
       "25%                  89.000000         4.000000           1011.000000   \n",
       "50%                 180.000000         8.000000           1023.000000   \n",
       "75%                 269.000000        12.000000           1035.000000   \n",
       "max                 359.000000        16.000000           1046.000000   \n",
       "\n",
       "       Condensation  Solar_irradiance_intensity  \n",
       "count         70938                70938.000000  \n",
       "unique            4                         NaN  \n",
       "top            Mist                         NaN  \n",
       "freq          21531                         NaN  \n",
       "mean            NaN                 1249.685162  \n",
       "std             NaN                  144.827495  \n",
       "min             NaN                 1000.000000  \n",
       "25%             NaN                 1124.000000  \n",
       "50%             NaN                 1249.000000  \n",
       "75%             NaN                 1375.000000  \n",
       "max             NaN                 1500.000000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe(include = \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To label encode the categorical varaibles in the target column to nominal variable.\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "    Train_data = data.copy()\n",
    "    label_ec = LabelEncoder()\n",
    "    label_ec.fit(list(Train_data['Cloud_Condition'].values))\n",
    "    Train_data['Cloud_Condition'] = label_ec.transform(list(Train_data['Cloud_Condition'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Cloud_Condition</th>\n",
       "      <th>Rain_OR_SNOW</th>\n",
       "      <th>Temperature_(C)</th>\n",
       "      <th>Apparent_Temperature_(C)</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind_Speed_(km/h)</th>\n",
       "      <th>Wind_Bearing_(degrees)</th>\n",
       "      <th>Visibility_(km)</th>\n",
       "      <th>Pressure_(millibars)</th>\n",
       "      <th>Condensation</th>\n",
       "      <th>Solar_irradiance_intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>rain</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>0.134364</td>\n",
       "      <td>17.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>Frost</td>\n",
       "      <td>1068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>rain</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.847434</td>\n",
       "      <td>8.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1036.0</td>\n",
       "      <td>Frost</td>\n",
       "      <td>1291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>rain</td>\n",
       "      <td>33.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>0.763775</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1004.0</td>\n",
       "      <td>Dry</td>\n",
       "      <td>1433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>snow</td>\n",
       "      <td>30.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.255069</td>\n",
       "      <td>15.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>Dry</td>\n",
       "      <td>1410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>snow</td>\n",
       "      <td>27.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.495435</td>\n",
       "      <td>63.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>Fog</td>\n",
       "      <td>1391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Day  Cloud_Condition Rain_OR_SNOW  Temperature_(C)  \\\n",
       "0    1               19         rain            -13.0   \n",
       "1    2               19         rain             15.0   \n",
       "2    3               19         rain             33.0   \n",
       "3    4               19         snow             30.0   \n",
       "4    5               19         snow             27.0   \n",
       "\n",
       "   Apparent_Temperature_(C)  Humidity  Wind_Speed_(km/h)  \\\n",
       "0                     -19.0  0.134364               17.0   \n",
       "1                       5.0  0.847434                8.0   \n",
       "2                     -12.0  0.763775               32.0   \n",
       "3                      36.0  0.255069               15.0   \n",
       "4                      30.0  0.495435               63.0   \n",
       "\n",
       "   Wind_Bearing_(degrees)  Visibility_(km)  Pressure_(millibars) Condensation  \\\n",
       "0                    68.0              4.0                1008.0        Frost   \n",
       "1                   291.0              2.0                1036.0        Frost   \n",
       "2                    32.0              8.0                1004.0          Dry   \n",
       "3                   130.0              3.0                1016.0          Dry   \n",
       "4                    60.0             15.0                1007.0          Fog   \n",
       "\n",
       "   Solar_irradiance_intensity  \n",
       "0                        1068  \n",
       "1                        1291  \n",
       "2                        1433  \n",
       "3                        1410  \n",
       "4                        1391  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To do one hot coding of the categorical input varaibles.\n",
    "Train_data=pd.get_dummies(Train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Cloud_Condition</th>\n",
       "      <th>Temperature_(C)</th>\n",
       "      <th>Apparent_Temperature_(C)</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind_Speed_(km/h)</th>\n",
       "      <th>Wind_Bearing_(degrees)</th>\n",
       "      <th>Visibility_(km)</th>\n",
       "      <th>Pressure_(millibars)</th>\n",
       "      <th>Solar_irradiance_intensity</th>\n",
       "      <th>Rain_OR_SNOW_rain</th>\n",
       "      <th>Rain_OR_SNOW_snow</th>\n",
       "      <th>Condensation_Dry</th>\n",
       "      <th>Condensation_Fog</th>\n",
       "      <th>Condensation_Frost</th>\n",
       "      <th>Condensation_Mist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>0.134364</td>\n",
       "      <td>17.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>1068</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.847434</td>\n",
       "      <td>8.0</td>\n",
       "      <td>291.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1036.0</td>\n",
       "      <td>1291</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>33.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>0.763775</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1004.0</td>\n",
       "      <td>1433</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>30.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.255069</td>\n",
       "      <td>15.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>1410</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>27.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.495435</td>\n",
       "      <td>63.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>1391</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Day  Cloud_Condition  Temperature_(C)  Apparent_Temperature_(C)  Humidity  \\\n",
       "0    1               19            -13.0                     -19.0  0.134364   \n",
       "1    2               19             15.0                       5.0  0.847434   \n",
       "2    3               19             33.0                     -12.0  0.763775   \n",
       "3    4               19             30.0                      36.0  0.255069   \n",
       "4    5               19             27.0                      30.0  0.495435   \n",
       "\n",
       "   Wind_Speed_(km/h)  Wind_Bearing_(degrees)  Visibility_(km)  \\\n",
       "0               17.0                    68.0              4.0   \n",
       "1                8.0                   291.0              2.0   \n",
       "2               32.0                    32.0              8.0   \n",
       "3               15.0                   130.0              3.0   \n",
       "4               63.0                    60.0             15.0   \n",
       "\n",
       "   Pressure_(millibars)  Solar_irradiance_intensity  Rain_OR_SNOW_rain  \\\n",
       "0                1008.0                        1068                  1   \n",
       "1                1036.0                        1291                  1   \n",
       "2                1004.0                        1433                  1   \n",
       "3                1016.0                        1410                  0   \n",
       "4                1007.0                        1391                  0   \n",
       "\n",
       "   Rain_OR_SNOW_snow  Condensation_Dry  Condensation_Fog  Condensation_Frost  \\\n",
       "0                  0                 0                 0                   1   \n",
       "1                  0                 0                 0                   1   \n",
       "2                  0                 1                 0                   0   \n",
       "3                  1                 1                 0                   0   \n",
       "4                  1                 0                 1                   0   \n",
       "\n",
       "   Condensation_Mist  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70938, 15)\n",
      "(70938,)\n"
     ]
    }
   ],
   "source": [
    "#Not splitting into train and test as the records for some clasess are very less, then splitting might not result in correct\n",
    "#distribution of the clasess.\n",
    "Train_X = Train_data.drop(['Cloud_Condition'], axis = 1).copy()\n",
    "Train_Y = Train_data['Cloud_Condition'].copy()\n",
    "\n",
    "print(Train_X.shape)\n",
    "print(Train_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# Standardization\n",
    "###################\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "Scaling = StandardScaler().fit(Train_X)\n",
    "Train_X_Std = Scaling.transform(Train_X) # This step standardizes the train input data\n",
    "\n",
    "\n",
    "# Add the column names to Train_X_Std\n",
    "Train_X_Std = pd.DataFrame(Train_X_Std, columns = Train_X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "#KNN - As the KNN algorithm works well and gives good accuracy with most of the classification problems, it is used in this case.\n",
    "###################\n",
    "\n",
    "KNN_Model_Def = KNeighborsClassifier(n_neighbors=3) # no of k is taken 3 as above this the accuracy is decreased.\n",
    "KNN_Model_Fit = KNN_Model_Def.fit(Train_X_Std, Train_Y)\n",
    "\n",
    "###################\n",
    "# Model prediction\n",
    "###################\n",
    "\n",
    "# Class Prediction\n",
    "Pred_KNN = KNN_Model_Fit.predict(Train_X_Std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 56.95395979587809\n",
      "Precision: 0.569539597958781\n",
      "Recall: 0.569539597958781\n",
      "F1-Score: 0.569539597958781\n"
     ]
    }
   ],
   "source": [
    "Confusion_Mat = confusion_matrix(Train_Y, Pred_KNN)\n",
    "\n",
    "print(f\"Accuracy: {sum(np.diagonal(Confusion_Mat))/Train_X.shape[0]*100}\")\n",
    "print(f\"Precision: {precision_score(Train_Y, Pred_KNN,average = 'micro')}\") # Precision [Total Positives/(Total Predicted Positives)]\n",
    "print(f\"Recall: {recall_score(Train_Y, Pred_KNN,average = 'micro')}\") # Recall (Also called TPR) [Total Positives/(Total Actual Positives)]\n",
    "print(f\"F1-Score: {f1_score(Train_Y, Pred_KNN,average ='micro')}\") # F1-Score [2*Precision*Recall/(Precision + Recall)] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# DT- A model with decision tree algorithm is built to check if there is any improvement in the accuracy.\n",
    "###################\n",
    "\n",
    "DT_Model_Def = DecisionTreeClassifier(random_state=123)\n",
    "DT_Model_Fit = DT_Model_Def.fit(Train_X_Std, Train_Y)\n",
    "\n",
    "###################\n",
    "# Model prediction\n",
    "###################\n",
    "\n",
    "# Class Prediction\n",
    "Pred_DT = DT_Model_Fit.predict(Train_X_Std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1-Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "Confusion_Mat = confusion_matrix(Train_Y, Pred_DT)\n",
    "\n",
    "print(f\"Accuracy: {sum(np.diagonal(Confusion_Mat))/Train_X.shape[0]*100}\")\n",
    "print(f\"Precision: {precision_score(Train_Y, Pred_DT,average = 'micro')}\") # Precision [Total Positives/(Total Predicted Positives)]\n",
    "print(f\"Recall: {recall_score(Train_Y, Pred_DT,average = 'micro')}\") # Recall (Also called TPR) [Total Positives/(Total Actual Positives)]\n",
    "print(f\"F1-Score: {f1_score(Train_Y, Pred_DT,average ='micro')}\") # F1-Score [2*Precision*Recall/(Precision + Recall)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# Random Forest -Now trying with an ensemble method to see if it increases the accuracy\n",
    "###################\n",
    "\n",
    "RF_Model_Def = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 42)\n",
    "RF_Model_Fit = RF_Model_Def.fit(Train_X_Std, Train_Y)\n",
    "\n",
    "###################\n",
    "# Model prediction\n",
    "###################\n",
    "\n",
    "# Class Prediction\n",
    "Pred_RF = RF_Model_Fit.predict(Train_X_Std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.89058050692154\n",
      "Precision: 0.9889058050692153\n",
      "Recall: 0.9889058050692153\n",
      "F1-Score: 0.9889058050692153\n"
     ]
    }
   ],
   "source": [
    "Confusion_Mat = confusion_matrix(Train_Y, Pred_RF)\n",
    "\n",
    "print(f\"Accuracy: {sum(np.diagonal(Confusion_Mat))/Train_X.shape[0]*100}\")\n",
    "print(f\"Precision: {precision_score(Train_Y, Pred_RF,average = 'micro')}\") # Precision [Total Positives/(Total Predicted Positives)]\n",
    "print(f\"Recall: {recall_score(Train_Y, Pred_RF,average = 'micro')}\") # Recall (Also called TPR) [Total Positives/(Total Actual Positives)]\n",
    "print(f\"F1-Score: {f1_score(Train_Y, Pred_RF,average ='micro')}\") # F1-Score [2*Precision*Recall/(Precision + Recall)] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though Decision tree and Random forest algorithms have given a better accuracy, we cannot decide the models are good as there may be overfitting since the model is trained and predicted on the same data.\n",
    "Other algorithm KNN has given a poor accuracy.\n",
    "\n",
    "So to increase the performance of the model the data need to be balanced, which can be achieved using the algorithm SMOTE to augment the dataset with artificial data by adding more data to the classes with lesser samples so that all the classes will have equal number of samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "To apply smote for oversampling, the minimum number of records needed for each class is two, but in the data there are two classes having only one record each. So before applying smote, manually one record for each of the minimum class is added similar to the existing data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Cloud_Condition</th>\n",
       "      <th>Rain_OR_SNOW</th>\n",
       "      <th>Temperature_(C)</th>\n",
       "      <th>Apparent_Temperature_(C)</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind_Speed_(km/h)</th>\n",
       "      <th>Wind_Bearing_(degrees)</th>\n",
       "      <th>Visibility_(km)</th>\n",
       "      <th>Pressure_(millibars)</th>\n",
       "      <th>Condensation</th>\n",
       "      <th>Solar_irradiance_intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11763</th>\n",
       "      <td>12182</td>\n",
       "      <td>Dangerously Windy and Partly Cloudy</td>\n",
       "      <td>rain</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.829716</td>\n",
       "      <td>59.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1041.0</td>\n",
       "      <td>Frost</td>\n",
       "      <td>1043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Day                      Cloud_Condition Rain_OR_SNOW  \\\n",
       "11763  12182  Dangerously Windy and Partly Cloudy         rain   \n",
       "\n",
       "       Temperature_(C)  Apparent_Temperature_(C)  Humidity  Wind_Speed_(km/h)  \\\n",
       "11763             16.0                      14.0  0.829716               59.0   \n",
       "\n",
       "       Wind_Bearing_(degrees)  Visibility_(km)  Pressure_(millibars)  \\\n",
       "11763                   269.0             11.0                1041.0   \n",
       "\n",
       "      Condensation  Solar_irradiance_intensity  \n",
       "11763        Frost                        1043  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[\"Cloud_Condition\"] == \"Dangerously Windy and Partly Cloudy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Newdata1 = {'Day' : 80001 , 'Cloud_Condition' : 'Dangerously Windy and Partly Cloudy', 'Rain_OR_SNOW' : 'rain' , \n",
    "          'Temperature_(C)' : 15.0, 'Apparent_Temperature_(C)' : 13.0, 'Humidity' : 0.79921, 'Wind_Speed_(km/h)' : 60,\n",
    "       'Wind_Bearing_(degrees)' : 270 , 'Visibility_(km)' : 12.0, 'Pressure_(millibars)' : 1040.0,\n",
    "       'Condensation' : 'Frost', 'Solar_irradiance_intensity' : 1044}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "New_data = data.append(Newdata1, ignore_index = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Cloud_Condition</th>\n",
       "      <th>Rain_OR_SNOW</th>\n",
       "      <th>Temperature_(C)</th>\n",
       "      <th>Apparent_Temperature_(C)</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind_Speed_(km/h)</th>\n",
       "      <th>Wind_Bearing_(degrees)</th>\n",
       "      <th>Visibility_(km)</th>\n",
       "      <th>Pressure_(millibars)</th>\n",
       "      <th>Condensation</th>\n",
       "      <th>Solar_irradiance_intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70934</th>\n",
       "      <td>79997</td>\n",
       "      <td>Foggy</td>\n",
       "      <td>rain</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.913108</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1031.0</td>\n",
       "      <td>Dry</td>\n",
       "      <td>1224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70935</th>\n",
       "      <td>79998</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "      <td>rain</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>0.496076</td>\n",
       "      <td>2.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>Frost</td>\n",
       "      <td>1463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70936</th>\n",
       "      <td>79999</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "      <td>rain</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.783161</td>\n",
       "      <td>44.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>Fog</td>\n",
       "      <td>1251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70937</th>\n",
       "      <td>80000</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "      <td>rain</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.191555</td>\n",
       "      <td>38.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>Fog</td>\n",
       "      <td>1258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70938</th>\n",
       "      <td>80001</td>\n",
       "      <td>Dangerously Windy and Partly Cloudy</td>\n",
       "      <td>rain</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.799210</td>\n",
       "      <td>60.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>Frost</td>\n",
       "      <td>1044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Day                      Cloud_Condition Rain_OR_SNOW  \\\n",
       "70934  79997                                Foggy         rain   \n",
       "70935  79998                        Mostly Cloudy         rain   \n",
       "70936  79999                        Mostly Cloudy         rain   \n",
       "70937  80000                        Mostly Cloudy         rain   \n",
       "70938  80001  Dangerously Windy and Partly Cloudy         rain   \n",
       "\n",
       "       Temperature_(C)  Apparent_Temperature_(C)  Humidity  Wind_Speed_(km/h)  \\\n",
       "70934              8.0                       4.0  0.913108                1.0   \n",
       "70935             28.0                     -22.0  0.496076                2.0   \n",
       "70936            -16.0                      -3.0  0.783161               44.0   \n",
       "70937            -15.0                       8.0  0.191555               38.0   \n",
       "70938             15.0                      13.0  0.799210               60.0   \n",
       "\n",
       "       Wind_Bearing_(degrees)  Visibility_(km)  Pressure_(millibars)  \\\n",
       "70934                   101.0              8.0                1031.0   \n",
       "70935                   149.0              7.0                1032.0   \n",
       "70936                   266.0             11.0                1019.0   \n",
       "70937                   154.0              6.0                1023.0   \n",
       "70938                   270.0             12.0                1040.0   \n",
       "\n",
       "      Condensation  Solar_irradiance_intensity  \n",
       "70934          Dry                        1224  \n",
       "70935        Frost                        1463  \n",
       "70936          Fog                        1251  \n",
       "70937          Fog                        1258  \n",
       "70938        Frost                        1044  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "New_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Cloud_Condition</th>\n",
       "      <th>Rain_OR_SNOW</th>\n",
       "      <th>Temperature_(C)</th>\n",
       "      <th>Apparent_Temperature_(C)</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind_Speed_(km/h)</th>\n",
       "      <th>Wind_Bearing_(degrees)</th>\n",
       "      <th>Visibility_(km)</th>\n",
       "      <th>Pressure_(millibars)</th>\n",
       "      <th>Condensation</th>\n",
       "      <th>Solar_irradiance_intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52706</th>\n",
       "      <td>53125</td>\n",
       "      <td>Windy and Dry</td>\n",
       "      <td>rain</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>0.923588</td>\n",
       "      <td>25.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1028.0</td>\n",
       "      <td>Dry</td>\n",
       "      <td>1485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Day Cloud_Condition Rain_OR_SNOW  Temperature_(C)  \\\n",
       "52706  53125   Windy and Dry         rain              6.0   \n",
       "\n",
       "       Apparent_Temperature_(C)  Humidity  Wind_Speed_(km/h)  \\\n",
       "52706                      -7.0  0.923588               25.0   \n",
       "\n",
       "       Wind_Bearing_(degrees)  Visibility_(km)  Pressure_(millibars)  \\\n",
       "52706                    45.0              4.0                1028.0   \n",
       "\n",
       "      Condensation  Solar_irradiance_intensity  \n",
       "52706          Dry                        1485  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[\"Cloud_Condition\"] == \"Windy and Dry\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Newdata2 = {'Day' : 80002 , 'Cloud_Condition' : 'Windy and Dry', 'Rain_OR_SNOW' : 'rain' , \n",
    "          'Temperature_(C)' : 7.0, 'Apparent_Temperature_(C)' : -8.0, 'Humidity' : 0.89921, 'Wind_Speed_(km/h)' : 26.0,\n",
    "       'Wind_Bearing_(degrees)' : 46.0 , 'Visibility_(km)' : 5.0, 'Pressure_(millibars)' : 1030.0,\n",
    "       'Condensation' : 'Dry', 'Solar_irradiance_intensity' : 1484}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "New_data = New_data.append(Newdata2, ignore_index = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Cloud_Condition</th>\n",
       "      <th>Rain_OR_SNOW</th>\n",
       "      <th>Temperature_(C)</th>\n",
       "      <th>Apparent_Temperature_(C)</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind_Speed_(km/h)</th>\n",
       "      <th>Wind_Bearing_(degrees)</th>\n",
       "      <th>Visibility_(km)</th>\n",
       "      <th>Pressure_(millibars)</th>\n",
       "      <th>Condensation</th>\n",
       "      <th>Solar_irradiance_intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70935</th>\n",
       "      <td>79998</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "      <td>rain</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>0.496076</td>\n",
       "      <td>2.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>Frost</td>\n",
       "      <td>1463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70936</th>\n",
       "      <td>79999</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "      <td>rain</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.783161</td>\n",
       "      <td>44.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>Fog</td>\n",
       "      <td>1251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70937</th>\n",
       "      <td>80000</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "      <td>rain</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.191555</td>\n",
       "      <td>38.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>Fog</td>\n",
       "      <td>1258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70938</th>\n",
       "      <td>80001</td>\n",
       "      <td>Dangerously Windy and Partly Cloudy</td>\n",
       "      <td>rain</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.799210</td>\n",
       "      <td>60.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>Frost</td>\n",
       "      <td>1044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70939</th>\n",
       "      <td>80002</td>\n",
       "      <td>Windy and Dry</td>\n",
       "      <td>rain</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>0.899210</td>\n",
       "      <td>26.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1030.0</td>\n",
       "      <td>Dry</td>\n",
       "      <td>1484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Day                      Cloud_Condition Rain_OR_SNOW  \\\n",
       "70935  79998                        Mostly Cloudy         rain   \n",
       "70936  79999                        Mostly Cloudy         rain   \n",
       "70937  80000                        Mostly Cloudy         rain   \n",
       "70938  80001  Dangerously Windy and Partly Cloudy         rain   \n",
       "70939  80002                        Windy and Dry         rain   \n",
       "\n",
       "       Temperature_(C)  Apparent_Temperature_(C)  Humidity  Wind_Speed_(km/h)  \\\n",
       "70935             28.0                     -22.0  0.496076                2.0   \n",
       "70936            -16.0                      -3.0  0.783161               44.0   \n",
       "70937            -15.0                       8.0  0.191555               38.0   \n",
       "70938             15.0                      13.0  0.799210               60.0   \n",
       "70939              7.0                      -8.0  0.899210               26.0   \n",
       "\n",
       "       Wind_Bearing_(degrees)  Visibility_(km)  Pressure_(millibars)  \\\n",
       "70935                   149.0              7.0                1032.0   \n",
       "70936                   266.0             11.0                1019.0   \n",
       "70937                   154.0              6.0                1023.0   \n",
       "70938                   270.0             12.0                1040.0   \n",
       "70939                    46.0              5.0                1030.0   \n",
       "\n",
       "      Condensation  Solar_irradiance_intensity  \n",
       "70935        Frost                        1463  \n",
       "70936          Fog                        1251  \n",
       "70937          Fog                        1258  \n",
       "70938        Frost                        1044  \n",
       "70939          Dry                        1484  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "New_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "    New_Train_data = New_data.copy()\n",
    "    label_ec = LabelEncoder()\n",
    "    label_ec.fit(list(New_Train_data['Cloud_Condition'].values))\n",
    "    New_Train_data['Cloud_Condition'] = label_ec.transform(list(New_Train_data['Cloud_Condition'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To do one hot coding of the categorical input varaibles.\n",
    "New_Train_data=pd.get_dummies(New_Train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70940, 15)\n",
      "(70940,)\n"
     ]
    }
   ],
   "source": [
    "New_Train_X = New_Train_data.drop(['Cloud_Condition'], axis = 1).copy()\n",
    "New_Train_Y = New_Train_data['Cloud_Condition'].copy()\n",
    "\n",
    "print(New_Train_X.shape)\n",
    "print(New_Train_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# Standardization\n",
    "###################\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "Scaling = StandardScaler().fit(New_Train_X)\n",
    "New_Train_X_Std = Scaling.transform(New_Train_X) # This step standardizes the train input data\n",
    "\n",
    "# Add the column names to Train_X_Std\n",
    "New_Train_X_Std = pd.DataFrame(New_Train_X_Std, columns = New_Train_X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(k_neighbors=1)\n",
    "SM_TrainInput, SM_TrainOutput = sm.fit_resample(New_Train_X_Std, New_Train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(568360, 15) (568360,)\n"
     ]
    }
   ],
   "source": [
    "print(SM_TrainInput.shape, SM_TrainOutput.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25    21860\n",
       "24    21860\n",
       "1     21860\n",
       "2     21860\n",
       "3     21860\n",
       "4     21860\n",
       "5     21860\n",
       "6     21860\n",
       "7     21860\n",
       "8     21860\n",
       "9     21860\n",
       "10    21860\n",
       "11    21860\n",
       "12    21860\n",
       "13    21860\n",
       "14    21860\n",
       "15    21860\n",
       "16    21860\n",
       "17    21860\n",
       "18    21860\n",
       "19    21860\n",
       "20    21860\n",
       "21    21860\n",
       "22    21860\n",
       "23    21860\n",
       "0     21860\n",
       "Name: Cloud_Condition, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now all the classes have the same number of samples.\n",
    "SM_TrainOutput.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train  (454688, 15)\n",
      "x_test  (113672, 15)\n",
      "y_train  (454688,)\n",
      "y_test  (113672,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train, y_test = train_test_split(SM_TrainInput, SM_TrainOutput, train_size = 0.8, random_state = 123)\n",
    "print(\"x_train \",x_train.shape)\n",
    "print(\"x_test \",x_test.shape)\n",
    "print(\"y_train \",y_train.shape)\n",
    "print(\"y_test \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# DT\n",
    "###################\n",
    "\n",
    "DT_Model_Def = DecisionTreeClassifier(random_state=123)\n",
    "DT_Model_Fit = DT_Model_Def.fit(x_train,y_train)\n",
    "\n",
    "###################\n",
    "# Model prediction\n",
    "###################\n",
    "\n",
    "# Class Prediction\n",
    "Pred_DT = DT_Model_Fit.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 89.15564079104793\n",
      "Precision: 0.8915564079104793\n",
      "Recall: 0.8915564079104793\n",
      "F1-Score: 0.8915564079104793\n"
     ]
    }
   ],
   "source": [
    "Confusion_Mat = confusion_matrix(y_test, Pred_DT)\n",
    "\n",
    "print(f\"Accuracy: {sum(np.diagonal(Confusion_Mat))/x_test.shape[0]*100}\")\n",
    "print(f\"Precision: {precision_score(y_test, Pred_DT,average = 'micro')}\") # Precision [Total Positives/(Total Predicted Positives)]\n",
    "print(f\"Recall: {recall_score(y_test, Pred_DT,average = 'micro')}\") # Recall (Also called TPR) [Total Positives/(Total Actual Positives)]\n",
    "print(f\"F1-Score: {f1_score(y_test, Pred_DT,average ='micro')}\") # F1-Score [2*Precision*Recall/(Precision + Recall)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# Random Forest -Now trying with an ensemble method to see if it increases the accuracy\n",
    "###################\n",
    "\n",
    "RF_Model_Def = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 42)\n",
    "RF_Model_Fit = RF_Model_Def.fit(x_train,y_train)\n",
    "\n",
    "###################\n",
    "# Model prediction\n",
    "###################\n",
    "\n",
    "# Class Prediction\n",
    "Pred_RF = RF_Model_Fit.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 91.63206418467169\n",
      "Precision: 0.9163206418467169\n",
      "Recall: 0.9163206418467169\n",
      "F1-Score: 0.9163206418467169\n"
     ]
    }
   ],
   "source": [
    "Confusion_Mat = confusion_matrix(y_test, Pred_RF)\n",
    "\n",
    "print(f\"Accuracy: {sum(np.diagonal(Confusion_Mat))/x_test.shape[0]*100}\")\n",
    "print(f\"Precision: {precision_score(y_test, Pred_RF,average = 'micro')}\") # Precision [Total Positives/(Total Predicted Positives)]\n",
    "print(f\"Recall: {recall_score(y_test, Pred_RF,average = 'micro')}\") # Recall (Also called TPR) [Total Positives/(Total Actual Positives)]\n",
    "print(f\"F1-Score: {f1_score(y_test, Pred_RF,average ='micro')}\") # F1-Score [2*Precision*Recall/(Precision + Recall)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "#KNN - As the KNN algorithm works well and gives good accuracy with most of the classification problems, it is used in this case.\n",
    "###################\n",
    "\n",
    "KNN_Model_Def = KNeighborsClassifier(n_neighbors=3) # no of k is taken 3 as above this the accuracy is decreased.\n",
    "KNN_Model_Fit = KNN_Model_Def.fit(x_train,y_train)\n",
    "\n",
    "###################\n",
    "# Model prediction\n",
    "###################\n",
    "\n",
    "# Class Prediction\n",
    "Pred_KNN = KNN_Model_Fit.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 91.81328735308607\n",
      "Precision: 0.9181328735308607\n",
      "Recall: 0.9181328735308607\n",
      "F1-Score: 0.9181328735308607\n"
     ]
    }
   ],
   "source": [
    "Confusion_Mat = confusion_matrix(y_test, Pred_KNN)\n",
    "\n",
    "print(f\"Accuracy: {sum(np.diagonal(Confusion_Mat))/x_test.shape[0]*100}\")\n",
    "print(f\"Precision: {precision_score(y_test, Pred_KNN,average = 'micro')}\") # Precision [Total Positives/(Total Predicted Positives)]\n",
    "print(f\"Recall: {recall_score(y_test, Pred_KNN,average = 'micro')}\") # Recall (Also called TPR) [Total Positives/(Total Actual Positives)]\n",
    "print(f\"F1-Score: {f1_score(y_test, Pred_KNN,average ='micro')}\") # F1-Score [2*Precision*Recall/(Precision + Recall)] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though the accuracy score of Decision Tree and Random forest models seem to have decreased but previously it was predicted on the training data but now the prediction is done on a seperate test data, so it might seem the score is decreased but the model performance might have improved.\n",
    "The performance of the model using KNN algorithm has improved a lot.\n",
    "So the performance of the models have improved by using a balanced data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the analysis is done on the One vs rest and One vs one classifier using SVM and logistic regression algorithms, on the unbalanced data.\n",
    "As the OVR and OVO classifier works like a binary classifier the imbalance in the data should not affect the performance of the model. \n",
    "And by analysing the same model with the balanced data we can find if there is any improvement in the performance of the model because of the data balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since SVM takes longer time to compute with a larger data, have done undersampling to reduce the data.\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "strategy = {0:200, 1:200, 2:200, 3:200, 4:200, 5:200, 6:200,7:200,8:200,9:200,10:200,11:200,12:200,13:200,14:200,\n",
    "            15:200,16:200,17:200,18:200,19:200,20:200,21:200,22:200,23:200,24:200,25:200}\n",
    "\n",
    "under = RandomUnderSampler(sampling_strategy =strategy, random_state = 123, replacement = False)\n",
    "US_TrainInput, US_TrainOutput = under.fit_resample(SM_TrainInput, SM_TrainOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5200, 15) (5200,)\n"
     ]
    }
   ],
   "source": [
    "print(US_TrainInput.shape, US_TrainOutput.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train  (4160, 15)\n",
      "x_test  (1040, 15)\n",
      "y_train  (4160,)\n",
      "y_test  (1040,)\n"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train, y_test = train_test_split(US_TrainInput, US_TrainOutput, train_size = 0.8, random_state = 123)\n",
    "print(\"x_train \",x_train.shape)\n",
    "print(\"x_test \",x_test.shape)\n",
    "print(\"y_train \",y_train.shape)\n",
    "print(\"y_test \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# SVM\n",
    "###################\n",
    "\n",
    "SVM_Model_Def = SVC(decision_function_shape='ovo',kernel='linear')\n",
    "SVM_UBModel_Fit = SVM_Model_Def.fit(Train_X_Std, Train_Y) #Model with unbalanced data\n",
    "SVM_BModel_Fit = SVM_Model_Def.fit(x_train,y_train) #Model with balanced data\n",
    "\n",
    "###################\n",
    "# Model prediction\n",
    "###################\n",
    "\n",
    "# Class Prediction\n",
    "Pred_UBSVM = SVM_UBModel_Fit.predict(Train_X_Std)\n",
    "Pred_BSVM = SVM_BModel_Fit.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 5.346922664862274\n",
      "Precision: 0.05346922664862274\n",
      "Recall: 0.05346922664862274\n",
      "F1-Score: 0.05346922664862274\n"
     ]
    }
   ],
   "source": [
    "Confusion_Mat = confusion_matrix(Train_Y, Pred_UBSVM)\n",
    "\n",
    "print(f\"Accuracy: {sum(np.diagonal(Confusion_Mat))/Train_X.shape[0]*100}\")\n",
    "print(f\"Precision: {precision_score(Train_Y, Pred_UBSVM,average = 'micro')}\") # Precision [Total Positives/(Total Predicted Positives)]\n",
    "print(f\"Recall: {recall_score(Train_Y, Pred_UBSVM,average = 'micro')}\") # Recall (Also called TPR) [Total Positives/(Total Actual Positives)]\n",
    "print(f\"F1-Score: {f1_score(Train_Y, Pred_UBSVM,average ='micro')}\") # F1-Score [2*Precision*Recall/(Precision + Recall)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 47.30769230769231\n",
      "Precision: 0.47307692307692306\n",
      "Recall: 0.47307692307692306\n",
      "F1-Score: 0.47307692307692306\n"
     ]
    }
   ],
   "source": [
    "Confusion_Mat = confusion_matrix(y_test, Pred_BSVM)\n",
    "\n",
    "print(f\"Accuracy: {sum(np.diagonal(Confusion_Mat))/x_test.shape[0]*100}\")\n",
    "print(f\"Precision: {precision_score(y_test, Pred_BSVM,average = 'micro')}\") # Precision [Total Positives/(Total Predicted Positives)]\n",
    "print(f\"Recall: {recall_score(y_test, Pred_BSVM,average = 'micro')}\") # Recall (Also called TPR) [Total Positives/(Total Actual Positives)]\n",
    "print(f\"F1-Score: {f1_score(y_test, Pred_BSVM,average ='micro')}\") # F1-Score [2*Precision*Recall/(Precision + Recall)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# SVM\n",
    "###################\n",
    "\n",
    "SVM_Model_Def = SVC(kernel='linear')\n",
    "SVM_OVR_Model = OneVsRestClassifier(SVM_Model_Def)\n",
    "SVM_UBModel_Fit = SVM_OVR_Model.fit(Train_X_Std, Train_Y) #Model with unbalanced data\n",
    "SVM_BModel_Fit = SVM_OVR_Model.fit(x_train,y_train) #Model with balanced data\n",
    "\n",
    "###################\n",
    "# Model prediction\n",
    "###################\n",
    "\n",
    "# Class Prediction\n",
    "Pred_UBSVM = SVM_UBModel_Fit.predict(Train_X_Std)\n",
    "Pred_BSVM = SVM_BModel_Fit.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 3.211254898643886\n",
      "Precision: 0.03211254898643886\n",
      "Recall: 0.03211254898643886\n",
      "F1-Score: 0.03211254898643886\n"
     ]
    }
   ],
   "source": [
    "Confusion_Mat = confusion_matrix(Train_Y, Pred_UBSVM)\n",
    "\n",
    "print(f\"Accuracy: {sum(np.diagonal(Confusion_Mat))/Train_X.shape[0]*100}\")\n",
    "print(f\"Precision: {precision_score(Train_Y, Pred_UBSVM,average = 'micro')}\") # Precision [Total Positives/(Total Predicted Positives)]\n",
    "print(f\"Recall: {recall_score(Train_Y, Pred_UBSVM,average = 'micro')}\") # Recall (Also called TPR) [Total Positives/(Total Actual Positives)]\n",
    "print(f\"F1-Score: {f1_score(Train_Y, Pred_UBSVM,average ='micro')}\") # F1-Score [2*Precision*Recall/(Precision + Recall)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 29.71153846153846\n",
      "Precision: 0.2971153846153846\n",
      "Recall: 0.2971153846153846\n",
      "F1-Score: 0.2971153846153846\n"
     ]
    }
   ],
   "source": [
    "Confusion_Mat = confusion_matrix(y_test, Pred_BSVM)\n",
    "\n",
    "print(f\"Accuracy: {sum(np.diagonal(Confusion_Mat))/x_test.shape[0]*100}\")\n",
    "print(f\"Precision: {precision_score(y_test, Pred_BSVM,average = 'micro')}\") # Precision [Total Positives/(Total Predicted Positives)]\n",
    "print(f\"Recall: {recall_score(y_test, Pred_BSVM,average = 'micro')}\") # Recall (Also called TPR) [Total Positives/(Total Actual Positives)]\n",
    "print(f\"F1-Score: {f1_score(y_test, Pred_BSVM,average ='micro')}\") # F1-Score [2*Precision*Recall/(Precision + Recall)] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance of One Vs one and One Vs rest classfier on the unbalanced data is very poor.\n",
    "But comparatively the performance of the model with balanced data is more but still it is not good.\n",
    "And also One Vs one is giving a better classification than One Vs rest classifier.\n",
    "But the poor performance might be due to the wrong selection of the kernel option.\n",
    "For the reason of less computation and faster convergence, have used the kernel as linear, but the other kernels like \"polynomial or RBF\" might give a better multi classification performance. \n",
    "Due to hardware limitations could not try them as it is taking longer time to compute and converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# Logistic Regression\n",
    "###################\n",
    "\n",
    "LR_Model_Def = LogisticRegression(solver='lbfgs', max_iter=500)\n",
    "LR_OVO_Model = OneVsOneClassifier(LR_Model_Def)\n",
    "LR_UBModel_Fit = LR_OVO_Model.fit(Train_X_Std, Train_Y) #Model with unbalanced data\n",
    "LR_BModel_Fit = LR_OVO_Model.fit(x_train,y_train) #Model with balanced data\n",
    "\n",
    "###################\n",
    "# Model prediction\n",
    "###################\n",
    "\n",
    "# Class Prediction\n",
    "Pred_UBLR = LR_UBModel_Fit.predict(Train_X_Std)\n",
    "Pred_BLR = LR_BModel_Fit.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 4.611068820660295\n",
      "Precision: 0.04611068820660295\n",
      "Recall: 0.04611068820660295\n",
      "F1-Score: 0.04611068820660295\n"
     ]
    }
   ],
   "source": [
    "Confusion_Mat = confusion_matrix(Train_Y, Pred_UBLR)\n",
    "\n",
    "print(f\"Accuracy: {sum(np.diagonal(Confusion_Mat))/Train_X.shape[0]*100}\")\n",
    "print(f\"Precision: {precision_score(Train_Y, Pred_UBLR,average = 'micro')}\") # Precision [Total Positives/(Total Predicted Positives)]\n",
    "print(f\"Recall: {recall_score(Train_Y, Pred_UBLR,average = 'micro')}\") # Recall (Also called TPR) [Total Positives/(Total Actual Positives)]\n",
    "print(f\"F1-Score: {f1_score(Train_Y, Pred_UBLR,average ='micro')}\") # F1-Score [2*Precision*Recall/(Precision + Recall)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 43.07692307692308\n",
      "Precision: 0.4307692307692308\n",
      "Recall: 0.4307692307692308\n",
      "F1-Score: 0.43076923076923074\n"
     ]
    }
   ],
   "source": [
    "Confusion_Mat = confusion_matrix(y_test, Pred_BLR)\n",
    "\n",
    "print(f\"Accuracy: {sum(np.diagonal(Confusion_Mat))/x_test.shape[0]*100}\")\n",
    "print(f\"Precision: {precision_score(y_test, Pred_BLR,average = 'micro')}\") # Precision [Total Positives/(Total Predicted Positives)]\n",
    "print(f\"Recall: {recall_score(y_test, Pred_BLR,average = 'micro')}\") # Recall (Also called TPR) [Total Positives/(Total Actual Positives)]\n",
    "print(f\"F1-Score: {f1_score(y_test, Pred_BLR,average ='micro')}\") # F1-Score [2*Precision*Recall/(Precision + Recall)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# Logistic Regression\n",
    "###################\n",
    "\n",
    "LR_Model_Def = LogisticRegression(multi_class='ovr',solver='lbfgs',max_iter=500)\n",
    "LR_UBModel_Fit = LR_Model_Def.fit(Train_X_Std, Train_Y) #Model with unbalanced data\n",
    "LR_BModel_Fit = LR_Model_Def.fit(x_train,y_train) #Model with balanced data\n",
    "\n",
    "###################\n",
    "# Model prediction\n",
    "###################\n",
    "\n",
    "# Class Prediction\n",
    "Pred_UBLR = LR_UBModel_Fit.predict(Train_X_Std)\n",
    "Pred_BLR = LR_BModel_Fit.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 2.6628887197270856\n",
      "Precision: 0.026628887197270856\n",
      "Recall: 0.026628887197270856\n",
      "F1-Score: 0.026628887197270856\n"
     ]
    }
   ],
   "source": [
    "Confusion_Mat = confusion_matrix(Train_Y, Pred_UBLR)\n",
    "\n",
    "print(f\"Accuracy: {sum(np.diagonal(Confusion_Mat))/Train_X.shape[0]*100}\")\n",
    "print(f\"Precision: {precision_score(Train_Y, Pred_UBLR,average = 'micro')}\") # Precision [Total Positives/(Total Predicted Positives)]\n",
    "print(f\"Recall: {recall_score(Train_Y, Pred_UBLR,average = 'micro')}\") # Recall (Also called TPR) [Total Positives/(Total Actual Positives)]\n",
    "print(f\"F1-Score: {f1_score(Train_Y, Pred_UBLR,average ='micro')}\") # F1-Score [2*Precision*Recall/(Precision + Recall)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 38.17307692307692\n",
      "Precision: 0.3817307692307692\n",
      "Recall: 0.3817307692307692\n",
      "F1-Score: 0.38173076923076915\n"
     ]
    }
   ],
   "source": [
    "Confusion_Mat = confusion_matrix(y_test, Pred_BLR)\n",
    "\n",
    "print(f\"Accuracy: {sum(np.diagonal(Confusion_Mat))/x_test.shape[0]*100}\")\n",
    "print(f\"Precision: {precision_score(y_test, Pred_BLR,average = 'micro')}\") # Precision [Total Positives/(Total Predicted Positives)]\n",
    "print(f\"Recall: {recall_score(y_test, Pred_BLR,average = 'micro')}\") # Recall (Also called TPR) [Total Positives/(Total Actual Positives)]\n",
    "print(f\"F1-Score: {f1_score(y_test, Pred_BLR,average ='micro')}\") # F1-Score [2*Precision*Recall/(Precision + Recall)] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance of One Vs one and One Vs rest classfier on the unbalanced data is very poor.\n",
    "But comparatively the performance of the model with balanced data is more but still it is not good.\n",
    "And also One Vs one is giving a better classification than One Vs rest classifier.\n",
    "But the poor performance might be due to the reason that the classes are not linearly seperable or there are more number of classes.\n",
    "As logistic regression does not work well on a non-linear data and more number of classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now will apply linear discriminant analysis on both the unbalanced and balanced data and verify if it affects the performance \n",
    "of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "X_lda = lda.fit_transform(Train_X_Std, Train_Y) #Applying LDA on the unbalanced data\n",
    "New_X_lda = lda.fit_transform(SM_TrainInput, SM_TrainOutput) # Applying LDA on the balanced data\n",
    "Small_X_lda = lda.fit_transform(US_TrainInput, US_TrainOutput) # Applying LDA on the under sampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70938, 13) (568360, 13) (5200, 13)\n"
     ]
    }
   ],
   "source": [
    "print(X_lda.shape,New_X_lda.shape,Small_X_lda.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train  (454688, 13)\n",
      "x_test  (113672, 13)\n",
      "y_train  (454688,)\n",
      "y_test  (113672,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train, y_test = train_test_split(New_X_lda, SM_TrainOutput, train_size = 0.8, random_state = 123)\n",
    "print(\"x_train \",x_train.shape)\n",
    "print(\"x_test \",x_test.shape)\n",
    "print(\"y_train \",y_train.shape)\n",
    "print(\"y_test \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "#KNN - As the KNN algorithm works well and gives good accuracy with most of the classification problems, it is used in this case.\n",
    "###################\n",
    "\n",
    "KNN_Model_Def = KNeighborsClassifier(n_neighbors=3) # no of k is taken 3 as above this the accuracy is decreased.\n",
    "KNN_UBModel_Fit = KNN_Model_Def.fit(X_lda, Train_Y)\n",
    "KNN_BModel_Fit = KNN_Model_Def.fit(x_train,y_train)\n",
    "\n",
    "###################\n",
    "# Model prediction\n",
    "###################\n",
    "\n",
    "# Class Prediction\n",
    "Pred_UBKNN = KNN_UBModel_Fit.predict(X_lda)\n",
    "Pred_BKNN = KNN_BModel_Fit.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 17.18401984831825\n",
      "Precision: 0.1718401984831825\n",
      "Recall: 0.1718401984831825\n",
      "F1-Score: 0.1718401984831825\n"
     ]
    }
   ],
   "source": [
    "Confusion_Mat = confusion_matrix(Train_Y, Pred_UBKNN)\n",
    "\n",
    "print(f\"Accuracy: {sum(np.diagonal(Confusion_Mat))/X_lda.shape[0]*100}\")\n",
    "print(f\"Precision: {precision_score(Train_Y, Pred_UBKNN,average = 'micro')}\") # Precision [Total Positives/(Total Predicted Positives)]\n",
    "print(f\"Recall: {recall_score(Train_Y, Pred_UBKNN,average = 'micro')}\") # Recall (Also called TPR) [Total Positives/(Total Actual Positives)]\n",
    "print(f\"F1-Score: {f1_score(Train_Y, Pred_UBKNN,average ='micro')}\") # F1-Score [2*Precision*Recall/(Precision + Recall)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 91.82824266310085\n",
      "Precision: 0.9182824266310086\n",
      "Recall: 0.9182824266310086\n",
      "F1-Score: 0.9182824266310086\n"
     ]
    }
   ],
   "source": [
    "Confusion_Mat = confusion_matrix(y_test, Pred_BKNN)\n",
    "\n",
    "print(f\"Accuracy: {sum(np.diagonal(Confusion_Mat))/x_test.shape[0]*100}\")\n",
    "print(f\"Precision: {precision_score(y_test, Pred_BKNN,average = 'micro')}\") # Precision [Total Positives/(Total Predicted Positives)]\n",
    "print(f\"Recall: {recall_score(y_test, Pred_BKNN,average = 'micro')}\") # Recall (Also called TPR) [Total Positives/(Total Actual Positives)]\n",
    "print(f\"F1-Score: {f1_score(y_test, Pred_BKNN,average ='micro')}\") # F1-Score [2*Precision*Recall/(Precision + Recall)] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying LDA over the unbalanced data has reduced the performance further.\n",
    "But LDA on a balanced data has not impacted the performance much but only a very minimal increase is observed in the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train  (4160, 13)\n",
      "x_test  (1040, 13)\n",
      "y_train  (4160,)\n",
      "y_test  (1040,)\n"
     ]
    }
   ],
   "source": [
    "# LDA applied undersampled data for SVM and logistic regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train, y_test = train_test_split(Small_X_lda, US_TrainOutput, train_size = 0.8, random_state = 123)\n",
    "print(\"x_train \",x_train.shape)\n",
    "print(\"x_test \",x_test.shape)\n",
    "print(\"y_train \",y_train.shape)\n",
    "print(\"y_test \",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# SVM\n",
    "###################\n",
    "\n",
    "SVM_Model_Def = SVC(decision_function_shape='ovo',kernel='linear')\n",
    "SVM_UBModel_Fit = SVM_Model_Def.fit(X_lda, Train_Y) #Model with unbalanced data\n",
    "SVM_BModel_Fit = SVM_Model_Def.fit(x_train,y_train) #Model with balanced data\n",
    "\n",
    "###################\n",
    "# Model prediction\n",
    "###################\n",
    "\n",
    "# Class Prediction\n",
    "Pred_UBSVM = SVM_UBModel_Fit.predict(X_lda)\n",
    "Pred_BSVM = SVM_BModel_Fit.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 3.06464800248104\n",
      "Precision: 0.030646480024810397\n",
      "Recall: 0.030646480024810397\n",
      "F1-Score: 0.030646480024810397\n"
     ]
    }
   ],
   "source": [
    "Confusion_Mat = confusion_matrix(Train_Y, Pred_UBSVM)\n",
    "\n",
    "print(f\"Accuracy: {sum(np.diagonal(Confusion_Mat))/X_lda.shape[0]*100}\")\n",
    "print(f\"Precision: {precision_score(Train_Y, Pred_UBSVM,average = 'micro')}\") # Precision [Total Positives/(Total Predicted Positives)]\n",
    "print(f\"Recall: {recall_score(Train_Y, Pred_UBSVM,average = 'micro')}\") # Recall (Also called TPR) [Total Positives/(Total Actual Positives)]\n",
    "print(f\"F1-Score: {f1_score(Train_Y, Pred_UBSVM,average ='micro')}\") # F1-Score [2*Precision*Recall/(Precision + Recall)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 48.36538461538461\n",
      "Precision: 0.48365384615384616\n",
      "Recall: 0.48365384615384616\n",
      "F1-Score: 0.48365384615384616\n"
     ]
    }
   ],
   "source": [
    "Confusion_Mat = confusion_matrix(y_test, Pred_BSVM)\n",
    "\n",
    "print(f\"Accuracy: {sum(np.diagonal(Confusion_Mat))/x_test.shape[0]*100}\")\n",
    "print(f\"Precision: {precision_score(y_test, Pred_BSVM,average = 'micro')}\") # Precision [Total Positives/(Total Predicted Positives)]\n",
    "print(f\"Recall: {recall_score(y_test, Pred_BSVM,average = 'micro')}\") # Recall (Also called TPR) [Total Positives/(Total Actual Positives)]\n",
    "print(f\"F1-Score: {f1_score(y_test, Pred_BSVM,average ='micro')}\") # F1-Score [2*Precision*Recall/(Precision + Recall)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# Logistic Regression\n",
    "###################\n",
    "\n",
    "LR_Model_Def = LogisticRegression(solver='lbfgs', max_iter=500)\n",
    "LR_OVO_Model = OneVsOneClassifier(LR_Model_Def)\n",
    "LR_UBModel_Fit = LR_OVO_Model.fit(X_lda, Train_Y) #Model with unbalanced data\n",
    "LR_BModel_Fit = LR_OVO_Model.fit(x_train,y_train) #Model with balanced data\n",
    "\n",
    "###################\n",
    "# Model prediction\n",
    "###################\n",
    "\n",
    "# Class Prediction\n",
    "Pred_UBLR = LR_UBModel_Fit.predict(X_lda)\n",
    "Pred_BLR = LR_BModel_Fit.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 3.452310468296259\n",
      "Precision: 0.03452310468296259\n",
      "Recall: 0.03452310468296259\n",
      "F1-Score: 0.03452310468296259\n"
     ]
    }
   ],
   "source": [
    "Confusion_Mat = confusion_matrix(Train_Y, Pred_UBLR)\n",
    "\n",
    "print(f\"Accuracy: {sum(np.diagonal(Confusion_Mat))/X_lda.shape[0]*100}\")\n",
    "print(f\"Precision: {precision_score(Train_Y, Pred_UBLR,average = 'micro')}\") # Precision [Total Positives/(Total Predicted Positives)]\n",
    "print(f\"Recall: {recall_score(Train_Y, Pred_UBLR,average = 'micro')}\") # Recall (Also called TPR) [Total Positives/(Total Actual Positives)]\n",
    "print(f\"F1-Score: {f1_score(Train_Y, Pred_UBLR,average ='micro')}\") # F1-Score [2*Precision*Recall/(Precision + Recall)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 43.269230769230774\n",
      "Precision: 0.4326923076923077\n",
      "Recall: 0.4326923076923077\n",
      "F1-Score: 0.4326923076923077\n"
     ]
    }
   ],
   "source": [
    "Confusion_Mat = confusion_matrix(y_test, Pred_BLR)\n",
    "\n",
    "print(f\"Accuracy: {sum(np.diagonal(Confusion_Mat))/x_test.shape[0]*100}\")\n",
    "print(f\"Precision: {precision_score(y_test, Pred_BLR,average = 'micro')}\") # Precision [Total Positives/(Total Predicted Positives)]\n",
    "print(f\"Recall: {recall_score(y_test, Pred_BLR,average = 'micro')}\") # Recall (Also called TPR) [Total Positives/(Total Actual Positives)]\n",
    "print(f\"F1-Score: {f1_score(y_test, Pred_BLR,average ='micro')}\") # F1-Score [2*Precision*Recall/(Precision + Recall)] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance model was built on LDA applied unbalanced and balanced data using One Vs One classifier of SVM and logistic regression.\n",
    "Applying LDA over the unbalanced data has reduced the performance across all the three algorithms KNN, SVM and logistic regression.\n",
    "Similarly applying LDA on a balanced data has improved the performance in all the three algorithms though it is very minimal that might be due to the limitations in the algorithms.\n",
    "If the data quality is good and a correct algorithm is used LDA can improve the classification performance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three approaches tried to improve the performance of a model when the data is unbalanced were,\n",
    "1. Oversampling the data using Smote algorithm\n",
    "2. One Vs One or One Vs Rest classifiers\n",
    "3. Applying linear discriminant algorithm. \n",
    "\n",
    "Among them, the approach to balance the data seemed to improve the performance more than the other two methods.\n",
    "If the data is balanced then the other techniques with correct tuning parameters can improve the performance further.\n",
    "But if the data is imblanced applying any complex techniques might not give any improvement in the performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
